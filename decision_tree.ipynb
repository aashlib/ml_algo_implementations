{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,\n",
    "                 left = None,\n",
    "                 right = None,\n",
    "                 prediction = None,\n",
    "                 numSamples = None,\n",
    "                 featureSplit = None,\n",
    "                 threshold = None,\n",
    "                 samples = None\n",
    "                ):\n",
    "        \n",
    "        self.left = left\n",
    "        self.right = right  \n",
    "        self.prediction = prediction\n",
    "        self.featureSplit = featureSplit \n",
    "        self.threshold = threshold\n",
    "        self.samples = samples\n",
    "        \n",
    "class DecisionTree:\n",
    "    \n",
    "    def __init__(self, maxDepth = 10, minSamples = 2, minIG = None):\n",
    "        self.maxDepth = maxDepth\n",
    "        self.minSamples = minSamples\n",
    "        self.minIG = minIG\n",
    "        self.root = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        #recursively grows tree\n",
    "        self.root = self.__growTree(X, y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        #traverses fit tree for every observation in prediction set\n",
    "        return [self.__traverseTree(x, self.root) for x in X]\n",
    "    \n",
    "    def __growTree(self, X, y, depth=0):\n",
    "\n",
    "        numSamples, numFeatures = X.shape\n",
    "        \n",
    "        #check stopping criteria\n",
    "        if depth >= self.maxDepth or numSamples <= self.minSamples or len(set(y))==1:\n",
    "            return Node(prediction = self.__mostCommonClass(y), samples = X)\n",
    "        \n",
    "        #find best split\n",
    "        bestFeature, bestThreshold, IG = self.__bestSplit(X, y, numFeatures)\n",
    "        \n",
    "        #create child nodes based on best determined split\n",
    "        leftSplit, rightSplit = self.__split(X[:,bestFeature], bestThreshold)\n",
    "        \n",
    "        #continue growing tree\n",
    "        leftNode = self.__growTree(X[leftSplit], y[leftSplit], depth=depth+1)\n",
    "        rightNode = self.__growTree(X[rightSplit], y[rightSplit], depth=depth+1)\n",
    "    \n",
    "        return Node(left= leftNode,\n",
    "                    right=rightNode,\n",
    "                    featureSplit = bestFeature,\n",
    "                    threshold = bestThreshold,\n",
    "                    samples = X\n",
    "                   )\n",
    "        \n",
    "    \n",
    "    def __mostCommonClass(self, y):\n",
    "        #given a set of labeled data points, determines majority class. represents final prediction in leaf nodes\n",
    "        return Counter(y).most_common()[0][0]\n",
    "    \n",
    "    def __bestSplit(self, X, y, numFeatures):\n",
    "        \n",
    "        maxGain = None\n",
    "        \n",
    "        #iteratively run through all possible features, thresholds and find best split (max information gain) \n",
    "        for feature in range(numFeatures):\n",
    "            featureData = X[:, feature]\n",
    "            for threshold in self.__getThresholds(featureData):\n",
    "                #calculate information gain for current feature, threshold\n",
    "                IG = self.__informationGain(y, featureData, threshold)\n",
    "                \n",
    "                #store feature, threshold that produces largest information gain\n",
    "                if not maxGain or IG > maxGain:\n",
    "                    maxGain = IG\n",
    "                    bestFeature, bestThreshold = feature, threshold\n",
    "        \n",
    "        return  bestFeature, bestThreshold, maxGain  \n",
    "    \n",
    "    def __getThresholds(self, featureData):\n",
    "        #given a set of continuous values, determines possible thresholds to split values on (using midpoint of adjacent values)\n",
    "        allFeatureValues = np.sort(np.unique(featureData))\n",
    "        thresholds = []\n",
    "        for i in range(1, len(allFeatureValues)):\n",
    "            thresholds.append((allFeatureValues[i]+allFeatureValues[i-1])/2)\n",
    "        \n",
    "        return thresholds\n",
    "    \n",
    "    \n",
    "    def __informationGain(self, y, featureData, threshold):\n",
    "        # Information Gain = entropy of parent - weighted avg. entropy of children\n",
    "        parentEntropy = self.__entropy(y)\n",
    "        \n",
    "        #create children\n",
    "        leftNode, rightNode = self.__split(featureData, threshold)\n",
    "        \n",
    "        #caculate weighted avg. entropy of children\n",
    "        entropyLeft = self.__entropy(y[leftNode])\n",
    "        entropyRight = self.__entropy(y[rightNode])\n",
    "        weightedEntropyChildren = entropyLeft * len(leftNode)/len(y) + entropyRight * len(rightNode)/len(y)        \n",
    "        \n",
    "        #calculate final information gain\n",
    "        IG = parentEntropy - weightedEntropyChildren\n",
    "        \n",
    "        return IG\n",
    "    \n",
    "    def __entropy(self, y):\n",
    "        #calculates entropy of a set of labeled observations. entropy = 0 when all classes are homogeneous, 1 if class occurrence is 50/50\n",
    "        pX = np.bincount(y)/len(y)\n",
    "        return -1 *sum([p * np.log(p) for p in pX if p > 0])\n",
    "    \n",
    "    def __split(self, featureData, threshold):\n",
    "        #splits observations based on a given feature and threshold\n",
    "        leftNode, rightNode = np.where(featureData <= threshold), np.where(featureData > threshold)\n",
    "        return leftNode, rightNode\n",
    "    \n",
    "    def __traverseTree(self, x, node):\n",
    "        #given an observation X, traverses through tree to determine its class prediction\n",
    "        \n",
    "        if node.prediction is not None: #if node is a leaf node, return class prediction. else continue running through tree\n",
    "            return node.prediction\n",
    "        \n",
    "        elif x[node.featureSplit] <= node.threshold:\n",
    "            return self.__traverseTree(x, node.left)\n",
    "        \n",
    "        elif x[node.featureSplit] > node.threshold:\n",
    "            return self.__traverseTree(x, node.right)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTree()\n",
    "model.fit(X_train, Y_train)\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9122807017543859"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
